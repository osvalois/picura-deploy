name: Kubernetes Resource Management

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 0 * * 0'  # Run every Sunday at midnight
  workflow_dispatch:  # Allows manual execution

env:
  KUBECONFIG: ./kubeconfig.yaml
  GRAFANA_ADMIN_USER: ${{ secrets.GRAFANA_ADMIN_USER }}
  GRAFANA_ADMIN_PASSWORD: ${{ secrets.GRAFANA_ADMIN_PASSWORD }}

jobs:
  manage-kubernetes-resources:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up kubectl
      uses: azure/setup-kubectl@v1
      with:
        version: 'v1.24.0'  # Specify the kubectl version you need

    - name: Configure kubectl
      run: |
        echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $KUBECONFIG
        chmod 600 $KUBECONFIG

    - name: Debug - Print kubeconfig
      run: |
        echo "Content of kubeconfig (first and last 10 lines):"
        (head -n 10 $KUBECONFIG && echo "..." && tail -n 10 $KUBECONFIG) || echo "Failed to read kubeconfig"

    - name: Debug - Check kubectl config
      run: |
        echo "Current context:"
        kubectl config current-context || echo "Failed to get current context"
        echo "Available contexts:"
        kubectl config get-contexts || echo "Failed to get contexts"
        echo "Clusters:"
        kubectl config get-clusters || echo "Failed to get clusters"

    - name: Debug - Test connection
      run: |
        echo "Attempting to list nodes:"
        kubectl get nodes || echo "Failed to get nodes"
        echo "Attempting to get cluster info:"
        kubectl cluster-info || echo "Failed to get cluster info"

    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: 'v3.8.0'  # Specify the Helm version you need

    - name: Install or update Monitoring resources
      run: |
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo add grafana https://grafana.github.io/helm-charts
        helm repo update
        kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
        helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring || echo "Failed to install Prometheus"
        helm upgrade --install grafana grafana/grafana --namespace monitoring \
          --set adminUser="${GRAFANA_ADMIN_USER}" \
          --set adminPassword="${GRAFANA_ADMIN_PASSWORD}" || echo "Failed to install Grafana"

    - name: Install or update Logging resources
      run: |
        helm repo add elastic https://helm.elastic.co
        helm repo update
        kubectl create namespace logging --dry-run=client -o yaml | kubectl apply -f -
        helm upgrade --install elasticsearch elastic/elasticsearch --namespace logging || echo "Failed to install Elasticsearch"
        helm upgrade --install kibana elastic/kibana --namespace logging || echo "Failed to install Kibana"

    - name: Install or update Resource Management
      run: |
        helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
        helm repo update
        helm upgrade --install metrics-server metrics-server/metrics-server --namespace kube-system || echo "Failed to install Metrics Server"

    - name: Expose services
      run: |
        kubectl patch svc prometheus-kube-prometheus-prometheus -n monitoring -p '{"spec": {"type": "LoadBalancer"}}' || echo "Failed to expose Prometheus"
        kubectl patch svc grafana -n monitoring -p '{"spec": {"type": "LoadBalancer"}}' || echo "Failed to expose Grafana"
        kubectl patch svc elasticsearch-master -n logging -p '{"spec": {"type": "LoadBalancer"}}' || echo "Failed to expose Elasticsearch"
        kubectl patch svc kibana-kibana -n logging -p '{"spec": {"type": "LoadBalancer"}}' || echo "Failed to expose Kibana"

    - name: Wait for Load Balancers
      run: |
        echo "Waiting for Load Balancers to be assigned public IPs..."
        sleep 120  # Wait for two minutes for IPs to be assigned

    - name: Get and display public service URLs
      id: get_urls
      run: |
        PROMETHEUS_IP=$(kubectl get svc prometheus-kube-prometheus-prometheus -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Failed to get Prometheus IP")
        GRAFANA_IP=$(kubectl get svc grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Failed to get Grafana IP")
        ELASTICSEARCH_IP=$(kubectl get svc elasticsearch-master -n logging -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Failed to get Elasticsearch IP")
        KIBANA_IP=$(kubectl get svc kibana-kibana -n logging -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "Failed to get Kibana IP")

        echo "Public URLs:"
        echo "Prometheus: http://$PROMETHEUS_IP:9090"
        echo "Grafana: http://$GRAFANA_IP:80"
        echo "Elasticsearch: http://$ELASTICSEARCH_IP:9200"
        echo "Kibana: http://$KIBANA_IP:5601"

        echo "prometheus_url=http://$PROMETHEUS_IP:9090" >> $GITHUB_OUTPUT
        echo "grafana_url=http://$GRAFANA_IP:80" >> $GITHUB_OUTPUT
        echo "elasticsearch_url=http://$ELASTICSEARCH_IP:9200" >> $GITHUB_OUTPUT
        echo "kibana_url=http://$KIBANA_IP:5601" >> $GITHUB_OUTPUT

    - name: Create Release Notes
      if: success()
      run: |
        cat << EOF > release_notes.md
        # Service URLs

        ## Monitoring
        - Prometheus: ${{ steps.get_urls.outputs.prometheus_url }}
        - Grafana: ${{ steps.get_urls.outputs.grafana_url }}

        ## Logging
        - Elasticsearch: ${{ steps.get_urls.outputs.elasticsearch_url }}
        - Kibana: ${{ steps.get_urls.outputs.kibana_url }}

        Please note that you may need to use appropriate authentication to access these services.
        EOF
        cat release_notes.md

    - name: Create GitHub Release
      if: success()
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ github.run_number }}
        release_name: Service URLs ${{ github.run_number }}
        body_path: release_notes.md
        draft: false
        prerelease: false

    - name: Show resource usage
      if: success()
      run: |
        kubectl top nodes || echo "Failed to get node resource usage"
        kubectl top pods --all-namespaces || echo "Failed to get pod resource usage"

    - name: Clean up
      if: always()
      run: rm -f $KUBECONFIG